{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd89f16-fe74-4ffa-b77c-76c800a3498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 12:53:52.604211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import pygrib\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sys.path.insert(0, '/glade/u/home/ksha/OPT_NCAR/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/OPT_NCAR/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c928c4-d5ab-4c8f-8639-8297bb97c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c08089-581a-4050-ac00-db3f11c494d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================== #\n",
    "date_temp = datetime(2021, 1, 1, 0, 0)\n",
    "# ===================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2380a4-7140-45bf-9c96-f51d7effef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = [2, 3, 4, 5, 6, 7, 8,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b83b89e-0f2c-4797-a823-2d30f9f98b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_lead = len(leads)\n",
    "N_var = len(var_names)\n",
    "half_margin = int(input_size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e808fb-a80a-4f2d-80c2-f4edec82125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRRv4_STATS.hdf', 'r') as h5io:\n",
    "    mean_stats = h5io['mean_stats'][...]\n",
    "    std_stats = h5io['std_stats'][...]\n",
    "    max_stats = h5io['max_stats'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51c4a1b-9eed-4b0c-b9a7-2d8eb8dddfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'HRRR_domain.hdf', 'r') as h5io:\n",
    "    lon_3km = h5io['lon_3km'][...]\n",
    "    lat_3km = h5io['lat_3km'][...]\n",
    "    lon_80km = h5io['lon_80km'][...]\n",
    "    lat_80km = h5io['lat_80km'][...]\n",
    "    land_mask_80km = h5io['land_mask_80km'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d55d8412-aa10-43bd-b7dd-cf03cf22d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_80km_mask = lon_80km[land_mask_80km]\n",
    "lat_80km_mask = lat_80km[land_mask_80km]\n",
    "\n",
    "lon_minmax = [np.min(lon_80km_mask), np.max(lon_80km_mask)]\n",
    "lat_minmax = [np.min(lat_80km_mask), np.max(lat_80km_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e88d413-26cc-4481-ade1-2ac62f47f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_80km = lon_80km.shape\n",
    "shape_3km = lon_3km.shape\n",
    "\n",
    "indx_array = np.empty(shape_80km)\n",
    "indy_array = np.empty(shape_80km)\n",
    "\n",
    "gridTree = cKDTree(list(zip(lon_3km.ravel(), lat_3km.ravel()))) #KDTree_wraper(xgrid, ygrid)\n",
    "\n",
    "for xi in range(shape_80km[0]):\n",
    "    for yi in range(shape_80km[1]):\n",
    "        \n",
    "        temp_lon = lon_80km[xi, yi]\n",
    "        temp_lat = lat_80km[xi, yi]\n",
    "        \n",
    "        dist, indexes = gridTree.query(list(zip(np.array(temp_lon)[None], np.array(temp_lat)[None])))\n",
    "        indx_3km, indy_3km = np.unravel_index(indexes, shape_3km)\n",
    "        \n",
    "        indx_array[xi, yi] = indx_3km[0]\n",
    "        indy_array[xi, yi] = indy_3km[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c034d6b2-f285-468a-84eb-739e1ba64e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 12:53:59.757556: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-03-06 12:53:59.758858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-03-06 12:53:59.804423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-03-06 12:53:59.804468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-06 12:53:59.866410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-06 12:53:59.866445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-03-06 12:53:59.893846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-06 12:53:59.915666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-06 12:53:59.957994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-03-06 12:53:59.991254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-03-06 12:54:00.023389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-03-06 12:54:00.024014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-03-06 12:54:00.024567: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-06 12:54:00.024778: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-03-06 12:54:00.025122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-03-06 12:54:00.025146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-06 12:54:00.025158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-06 12:54:00.025169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-03-06 12:54:00.025179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-06 12:54:00.025189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-06 12:54:00.025199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-03-06 12:54:00.025209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-03-06 12:54:00.025219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-03-06 12:54:00.025716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-03-06 12:54:00.025742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-06 12:54:00.576500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-03-06 12:54:00.576546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-03-06 12:54:00.576556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-03-06 12:54:00.577534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /glade/work/ksha/NCAR/Keras_models/RE2_peak_base5/\n",
      "... done\n"
     ]
    }
   ],
   "source": [
    "# Crerate model\n",
    "model = mu.create_model(input_shape=(input_size, input_size, N_var))\n",
    "\n",
    "# get current weights\n",
    "W_new = model.get_weights()\n",
    "\n",
    "# get stored weights\n",
    "print('Loading weights from {}'.format(model_name))\n",
    "W_old = mu.dummy_loader(model_name)\n",
    "\n",
    "# update stored weights to new weights\n",
    "for i in range(len(W_new)):\n",
    "    if W_new[i].shape == W_old[i].shape:\n",
    "        W_new[i] = W_old[i]\n",
    "\n",
    "# dump new weights to the model\n",
    "model.set_weights(W_new)\n",
    "print('... done')\n",
    "# compile just in case\n",
    "#model.compile(loss=keras.losses.mean_absolute_error, optimizer=keras.optimizers.SGD(lr=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2931f-e21f-4530-8ea5-d50ac69b92d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting HRRR 3-km field into feature vectors\n",
      "Pre-rpocessing 2-hr forecasts ...\n",
      "HRRR quality control flag = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 12:55:06.840564: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-03-06 12:55:06.841090: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n",
      "2023-03-06 12:55:08.996680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-06 12:55:09.202436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 152.87898635864258 seconds ---\n",
      "...done\n",
      "Pre-rpocessing 3-hr forecasts ...\n",
      "HRRR quality control flag = True\n",
      "--- 116.63988208770752 seconds ---\n",
      "...done\n",
      "Pre-rpocessing 4-hr forecasts ...\n",
      "HRRR quality control flag = True\n",
      "--- 119.26793193817139 seconds ---\n",
      "...done\n",
      "Pre-rpocessing 5-hr forecasts ...\n",
      "HRRR quality control flag = True\n"
     ]
    }
   ],
   "source": [
    "VARs = np.empty(shape_3km+(N_var,))\n",
    "VARs[...] = np.nan\n",
    "\n",
    "FEATURE_VEC = np.empty(shape_80km+(N_lead, L_vec))\n",
    "FEATURE_VEC[...] = np.nan\n",
    "\n",
    "input_frame = np.empty((1, input_size, input_size, N_var))\n",
    "input_frame[...] = np.nan\n",
    "\n",
    "PROB = np.empty(shape_80km+(N_lead,))\n",
    "PROB[...] = np.nan\n",
    "\n",
    "print(\"Converting HRRR 3-km field into feature vectors\")\n",
    "\n",
    "for l in range(N_lead):\n",
    "    lead = leads[l]\n",
    "    print('Pre-rpocessing {}-hr forecasts ...'.format(lead))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    filename_grib = (datetime.strftime(date_temp, HRRR_dir+HRRR_name)).format(lead, lead)\n",
    "\n",
    "    var_names_temp = []\n",
    "    with pygrib.open(filename_grib) as grbio:\n",
    "        for i, ind in enumerate(HRRRv4_inds):\n",
    "            var_names_temp.append(str(grbio[ind])[:35])\n",
    "\n",
    "    flag_qc = var_names == var_names_temp\n",
    "    print(\"HRRR quality control flag = {}\".format(flag_qc))\n",
    "    \n",
    "    with pygrib.open(filename_grib) as grbio:\n",
    "        for i, ind in enumerate(HRRRv4_inds):\n",
    "            VARs[..., i] = grbio[ind].values\n",
    "        \n",
    "    for ix in range(shape_80km[0]):\n",
    "        for iy in range(shape_80km[1]):\n",
    "\n",
    "            indx = int(indx_array[ix, iy])\n",
    "            indy = int(indy_array[ix, iy])\n",
    "\n",
    "            x_edge_left = indx - half_margin\n",
    "            x_edge_right = indx + half_margin\n",
    "\n",
    "            y_edge_bottom = indy - half_margin\n",
    "            y_edge_top = indy + half_margin\n",
    "\n",
    "            if x_edge_left >= 0 and y_edge_bottom >= 0 and x_edge_right < shape_3km[0] and y_edge_top < shape_3km[1]:\n",
    "\n",
    "                hrrr_temp = VARs[x_edge_left:x_edge_right, y_edge_bottom:y_edge_top, :]\n",
    "\n",
    "                for n in range(N_var):\n",
    "\n",
    "                    means = mean_stats[ix, iy, n, l]\n",
    "                    stds = std_stats[ix, iy, n, l]\n",
    "                    max_vals = max_stats[ix, iy, n, l]\n",
    "\n",
    "                    temp = hrrr_temp[..., n]\n",
    "\n",
    "                    # (n==0) Radar reflectivity, correct negative to 0\n",
    "                    if n == 0:\n",
    "                        temp[temp<0] = 0\n",
    "\n",
    "                    # (n==10) CIN, preserve negative vals only, and convert them to positive \n",
    "                    if n == 10:\n",
    "                        temp = -1*temp\n",
    "                        temp[temp<0] = 0\n",
    "\n",
    "                    # variables that will be normalizaed with log transformation\n",
    "                    if log_norm[n]:\n",
    "                        temp = np.log(np.abs(temp)+1)\n",
    "                        # for CIN and SRH, x3 the value\n",
    "                        if n < 9:\n",
    "                            temp = temp/stds/max_vals\n",
    "                        else:\n",
    "                            temp = 3.0*temp/stds/max_vals\n",
    "\n",
    "                    else:\n",
    "                        temp = (temp - means)/stds\n",
    "\n",
    "                    input_frame[..., n] = temp\n",
    "\n",
    "                # CNN feature vectors\n",
    "\n",
    "                temp_vec = model.predict([input_frame])\n",
    "                FEATURE_VEC[ix, iy, l, :] = temp_vec[0, :]\n",
    "                \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('...done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e3c81-2716-4130-b97e-76bd5835d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(N_lead):\n",
    "    \n",
    "    lead = leads[l]\n",
    "    print('Estimating probabilities on {}-hr forecasts ...'.format(lead))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if l == 0:\n",
    "        N_vec = 2*2\n",
    "        lead_range = [0, 1]\n",
    "\n",
    "    elif l == 1:\n",
    "        N_vec = 3*2\n",
    "        lead_range = [0, 1, 2]\n",
    "\n",
    "    else:\n",
    "        N_vec = 4*2\n",
    "        lead_range = [l-2, l-1, l, l+1]\n",
    "    \n",
    "    # ======================================= #\n",
    "    # load classifier head\n",
    "    model_head = mu.create_model_head(N_vec, L_vec)\n",
    "    #W_new = model.get_weights()\n",
    "    W_old = mu.dummy_loader(model_head_name.format(lead))\n",
    "    model_head.set_weights(W_old)\n",
    "    # ======================================= #\n",
    "    \n",
    "    VEC_merge = np.empty((N_vec, L_vec))\n",
    "    VEC_merge[...] = np.nan\n",
    "    \n",
    "    for ix in range(shape_80km[0]):\n",
    "        for iy in range(shape_80km[1]):\n",
    "            \n",
    "            count = 0\n",
    "            #vec_merge = ()\n",
    "\n",
    "            indx_temp = ix\n",
    "            indy_temp = iy\n",
    "\n",
    "            indx_left = np.max([indx_temp - 1, 0])\n",
    "            indx_right = np.min([indx_temp + 1, shape_80km[0]-1])\n",
    "\n",
    "            indy_bot = np.max([indy_temp - 1, 0])\n",
    "            indy_top = np.min([indy_temp + 1, shape_80km[1]-1])\n",
    "                \n",
    "            for ix_vec in [indx_temp, indx_left, indx_right]:\n",
    "                for iy_vec in [indy_temp, indy_bot, indy_top]:\n",
    "                    for il in lead_range:\n",
    "                        vec_temp = FEATURE_VEC[ix_vec, iy_vec, il, :]\n",
    "                        if np.sum(np.isnan(vec_temp)) == 0 and count < N_vec:\n",
    "                            #vec_merge += (vec_temp[None, ...],)\n",
    "                            VEC_merge[count, :] = vec_temp\n",
    "                            count += 1\n",
    "                                \n",
    "            if count < N_vec:\n",
    "                continue\n",
    "            else:\n",
    "                #VEC_merge = np.concatenate(vec_merge, axis=0)\n",
    "                Input_vec = VEC_merge[None, ...]\n",
    "\n",
    "\n",
    "                lon = lon_80km[ix, iy]\n",
    "                lat = lat_80km[ix, iy]\n",
    "\n",
    "                lon = (lon - lon_minmax[0])/(lon_minmax[1] - lon_minmax[0])\n",
    "                lat = (lat - lat_minmax[0])/(lat_minmax[1] - lat_minmax[0])\n",
    "                Input_stn = np.array([lon, lat])\n",
    "                Input_stn = Input_stn[None, ...]\n",
    "\n",
    "                prob_raw = model_head.predict([Input_vec, Input_stn])\n",
    "                PROB[ix, iy, l] = prob_raw[0]\n",
    "                \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb42328-2e80-4114-8bfd-41dc886f27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_save = (FEATURE_VEC, PROB)\n",
    "label_save = ['FEATURE_VEC', 'PROB']\n",
    "du.save_hdf5(tuple_save, label_save, output_dir, datetime.strftime(date_temp, output name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ad0e2-1948-4efa-857a-bdbff0a1e6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed2056-0d2d-47bb-9734-29e19dd0ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d9af2-0c47-475a-bf6d-64c310073ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(FEATURE_VEC[..., 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f16566-5bb6-475c-ade5-3e02b1d0e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(PROB[..., 0], vmin=0, vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f25ec8-9ef4-4fb3-91b7-6706b789b740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
